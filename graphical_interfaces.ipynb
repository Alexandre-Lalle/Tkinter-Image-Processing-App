{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6eed51b0",
   "metadata": {},
   "source": [
    "Réalisé par :\n",
    "    - MOUHSINE Abdelghaffour\n",
    "    - LALLE Yendoubouam Alexandre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7aaaac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image, ImageOps\n",
    "from tkinter import filedialog\n",
    "import matplotlib.pyplot as plt\n",
    "from tkinter import simpledialog\n",
    "from tkinter import messagebox\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a83864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcourir_image():\n",
    "    global tkimage1,chemin_image_originale\n",
    "    # Ouvre une fenêtre de dialogue pour sélectionner un fichier image\n",
    "    chemin_image_originale = filedialog.askopenfilename()\n",
    "    image_originale = Image.open(chemin_image_originale)\n",
    "    image_originale = image_originale.resize((500, 500), Image.ANTIALIAS)\n",
    "    tkimage1 = ImageTk.PhotoImage(image_originale)\n",
    "    # Affiche l'image dilatée dans le canevas\n",
    "    canvas1.itemconfig(canvas1_image, image=tkimage1)\n",
    "    \n",
    "def afficher_image_resultante(image_opencv):\n",
    "    global tkimage2 , image2\n",
    "    image2 = image_opencv\n",
    "    # Convertit l'image dilatée en format compatible avec PIL\n",
    "    image_opencv = Image.fromarray(image_opencv)\n",
    "    image_opencv=image_opencv.resize((500, 500), Image.ANTIALIAS)\n",
    "    # pour eleminer l'erreur \"image \"pyimage3\" doesn't exist\"\n",
    "    # Conversion de l'image en format compatible avec tkinter\n",
    "    tkimage2 = ImageTk.PhotoImage(image_opencv)\n",
    "    # Affiche l'image dilatée dans le canevas\n",
    "    canvas2.itemconfig(canvas2_image, image=tkimage2)\n",
    "   \n",
    "def sauvegarder_dialog():\n",
    "    nom = simpledialog.askstring(\"seuil :\", \"Entrez le nom du fichier.jpg : \")\n",
    "    if nom is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le nom ne peut pas être nulle.\")\n",
    "    else :\n",
    "        return nom\n",
    "    \n",
    "def sauvegarder():\n",
    "    global image2\n",
    "    nom = sauvegarder_dialog()\n",
    "    cv2.imwrite(f'./images_resultats/{nom}',image2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebefa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_image_negative():\n",
    "    global chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_originale = Image.open(chemin_image_originale)\n",
    "    # Calcule l'image négative\n",
    "    image_negative = ImageOps.invert(image_originale)\n",
    "    # Convertir l'image négative en numpy array\n",
    "    image_negative_cv2 = np.array(image_negative)\n",
    "    afficher_image_resultante(image_negative_cv2) \n",
    "    \n",
    "def rotation_degree_dialog():\n",
    "    size = simpledialog.askinteger(\"degree :\", \"Entrez la valeur de degree : \", minvalue=0)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le degree ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, int):\n",
    "        messagebox.showerror(\"Erreur\", \"le degree doit être un entier.\")\n",
    "    else :\n",
    "        return size   \n",
    " \n",
    "def rotation_degree_dialog():\n",
    "    size = simpledialog.askfloat(\"le degree :\", \"Entrez un degree : \", minvalue=0 , maxvalue=100)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le degree ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, float):\n",
    "        messagebox.showerror(\"Erreur\", \"le degree doit être un reel.\")\n",
    "    else :\n",
    "        return size\n",
    "   \n",
    "\n",
    "def app_rotation_degree():\n",
    "    global chemin_image_originale\n",
    "    # Lire l'image originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    # Calculer la matrice de transformation de rotation\n",
    "    rows, cols = image_opencv.shape[:2]\n",
    "    angle = rotation_degree_dialog()\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "    # Appliquer la transformation à l'image\n",
    "    rotated_img = cv2.warpAffine(image_opencv, M, (cols, rows))   \n",
    "    afficher_image_resultante(rotated_img)\n",
    "    \n",
    "def redimensionner_nouvelletaille_dialog():\n",
    "    size = simpledialog.askinteger(\"seuil :\", \"Entrez une nouvelle taille : \", minvalue=0)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"La nouvelle taille ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, int):\n",
    "        messagebox.showerror(\"Erreur\", \"la nouvelle taille doit être un entier.\")\n",
    "    else :\n",
    "        return size\n",
    "    \n",
    "def app_Redimensionner_nouvelletaille():\n",
    "    global chemin_image_originale, tkimage2, image2\n",
    "    # lire l'image\n",
    "    image_originale = Image.open(chemin_image_originale)\n",
    "    # Redimensionner l'image en spécifiant une nouvelle taille\n",
    "    size = redimensionner_nouvelletaille_dialog()\n",
    "    new_size = (size, size)\n",
    "    resized_image = image_originale.resize(new_size)\n",
    "    # Conversion de l'image en format compatible avec tkinter\n",
    "    image2 = resized_image\n",
    "    tkimage2 = ImageTk.PhotoImage(resized_image)\n",
    "    # Affiche l'image dans le canevas\n",
    "    canvas2.itemconfig(canvas2_image, image=tkimage2)\n",
    "\n",
    "def redimensionner_pourcentage_dialog():\n",
    "    size = simpledialog.askfloat(\"la  nouvelle taille :\", \"Entrez un pourcentage : \", minvalue=0 , maxvalue=100)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le pourcentage ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, float):\n",
    "        messagebox.showerror(\"Erreur\", \"le pourcentage doit être un reel.\")\n",
    "    else :\n",
    "        return size\n",
    "    \n",
    "def app_Redimensionner_pourcentage():\n",
    "    global chemin_image_originale, tkimage2, image2\n",
    "    image_originale = Image.open(chemin_image_originale)\n",
    "    image_originale = image_originale.resize((500,500))\n",
    "    percent = redimensionner_pourcentage_dialog() \n",
    "    with_ = int(image_originale.width * (percent / 100))\n",
    "    height_ = int(image_originale.height * (percent / 100))\n",
    "    resized_image = image_originale.resize((with_,height_))\n",
    "    # Conversion de l'image en format compatible avec tkinter\n",
    "    image2 = resized_image\n",
    "    tkimage2 = ImageTk.PhotoImage(resized_image)\n",
    "    # Affiche l'image dans le canevas\n",
    "    canvas2.itemconfig(canvas2_image, image=tkimage2)\n",
    "\n",
    "    \n",
    "def app_histogramme():\n",
    "    global chemin_image_originale \n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    fig = plt.figure()\n",
    "    if(len(img.shape) == 2):\n",
    "        # Calculer et Afficher les histogrammes de l'image en niveaux de gris \n",
    "        plt.hist(img.ravel(), 256, [0, 256], color='b')\n",
    "        plt.title('Histogramme Niveaux de gris')\n",
    "\n",
    "    else:\n",
    "        # Diviser l'image en canaux BGR\n",
    "        b, g, r = cv2.split(img)\n",
    "        # Afficher l'histogramme de chaque canal\n",
    "        plt.hist(b.ravel(), 50, [0, 256], color='b')\n",
    "        plt.hist(g.ravel(), 50, [0, 256], color='g')\n",
    "        plt.hist(r.ravel(), 50, [0, 256], color='r')\n",
    "        plt.title('Histogramme Couleurs')\n",
    "\n",
    "    #plt.show()\n",
    "    # Convertir la figure en image array\n",
    "    canvas = fig.canvas\n",
    "    canvas.draw()\n",
    "    w, h = canvas.get_width_height()\n",
    "    img_fig = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    img_fig = img_fig.reshape(h, w, 3)\n",
    "    afficher_image_resultante(img_fig) \n",
    "    \n",
    "    \n",
    "def app_egalisation():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    if len(image_opencv.shape) == 2:\n",
    "        img_egaliser = cv2.equalizeHist(image_opencv)\n",
    "    else:\n",
    "        r = image_opencv[:,:,0]\n",
    "        g = image_opencv[:,:,1]\n",
    "        b = image_opencv[:,:,2]\n",
    "        b_egaliser = cv2.equalizeHist(b)\n",
    "        g_egaliser = cv2.equalizeHist(g)\n",
    "        r_egaliser = cv2.equalizeHist(r)\n",
    "        # Fusionner les canaux de couleur\n",
    "        img_egaliser = cv2.merge((b_egaliser, g_egaliser, r_egaliser))\n",
    "    afficher_image_resultante(img_egaliser)\n",
    "    \n",
    "            \n",
    "def app_etirement():\n",
    "    global chemin_image_originale\n",
    "    \n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    print(f'len_shape : {len(image_opencv.shape)} and shape = {image_opencv.shape}')\n",
    "    if len(image_opencv.shape) == 2:\n",
    "        # Calcul des valeurs minimales et maximales des pixels\n",
    "        min_value = np.min(image_opencv)\n",
    "        max_value = np.max(image_opencv)\n",
    "        # Etirement de l'image\n",
    "        image_etirer = ((image_opencv - min_value) * (255 / (max_value - min_value))).astype(np.uint8)\n",
    "    else:\n",
    "        r = image_opencv[:,:,0]\n",
    "        g = image_opencv[:,:,1]\n",
    "        b = image_opencv[:,:,2]\n",
    "        min_value = np.min(b)\n",
    "        max_value = np.max(b)\n",
    "        b_etirer = ((b - min_value) * (255 / (max_value - min_value))).astype(np.uint8)\n",
    "        min_value = np.min(g)\n",
    "        max_value = np.max(g)\n",
    "        g_etirer = ((g - min_value) * (255 / (max_value - min_value))).astype(np.uint8)\n",
    "        min_value = np.min(r)\n",
    "        max_value = np.max(r)\n",
    "        r_etirer = ((r - min_value) * (255 / (max_value - min_value))).astype(np.uint8)\n",
    "        # Fusionner les canaux de couleur\n",
    "        image_etirer = cv2.merge((b_etirer, g_etirer, r_etirer))\n",
    "    afficher_image_resultante(image_etirer)\n",
    "    \n",
    "def binarisation_globale_seuillage_manuel_dialog():\n",
    "    #fenetre.withdraw()  # cache la fenêtre principale\n",
    "    size = simpledialog.askinteger(\"seuil :\", \"Entrez le seuil de binarisation : \", minvalue=0, maxvalue=255)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le seuil ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, int):\n",
    "        messagebox.showerror(\"Erreur\", \"Le seuil doit être un entier.\")\n",
    "    else :\n",
    "        #fenetre.deiconify()  # affiche la fenêtre principale\n",
    "        return size\n",
    "    \n",
    "def app_binarisation_globale_seuillage_manuel():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    seuil = binarisation_globale_seuillage_manuel_dialog()\n",
    "    _, img_bin_manual = cv2.threshold(image_opencv, seuil, 255, cv2.THRESH_BINARY)\n",
    "    afficher_image_resultante(img_bin_manual)\n",
    "    \n",
    "def app_binarisation_globale_algorithme_Otsu():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_bin_otsu = cv2.threshold(image_opencv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    afficher_image_resultante(img_bin_otsu)\n",
    " \n",
    "\n",
    "def element_structurant_dialog():\n",
    "    size = simpledialog.askinteger(\"element structurant :\", \"Entrez la taille d'element structurant : \", minvalue=0, maxvalue=255)\n",
    "    if size is None:\n",
    "        messagebox.showerror(\"Erreur\", \"la taille d'element structurant ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, int) or (size % 2 == 0) :\n",
    "        messagebox.showerror(\"Erreur\", \"la taille d'element structurant doit être un entier impaire.\")\n",
    "    else :\n",
    "        return size\n",
    "    \n",
    "def app_erosion():\n",
    "    global tkimage2,chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    # Convertit l'image en niveau de gris\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    # Applique une dilatation sur l'image avec OpenCV\n",
    "    taille_ele_struct = element_structurant_dialog()\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (taille_ele_struct,taille_ele_struct))\n",
    "    image_erosion = cv2.erode(image_opencv, element_structurant, iterations=1)\n",
    "    afficher_image_resultante(image_erosion)\n",
    "    \n",
    "def app_delatation():\n",
    "    global tkimage2,chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    taille_ele_struct = element_structurant_dialog()\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (taille_ele_struct,taille_ele_struct))\n",
    "    image_dilatee_opencv = cv2.dilate(image_opencv, element_structurant, iterations=1)\n",
    "    afficher_image_resultante(image_dilatee_opencv)\n",
    "\n",
    "def app_ouverture():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    taille_ele_struct = element_structurant_dialog()\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (taille_ele_struct,taille_ele_struct))\n",
    "    image_ouverture = cv2.morphologyEx(image_opencv, cv2.MORPH_OPEN, element_structurant)\n",
    "    afficher_image_resultante(image_ouverture)\n",
    "\n",
    " \n",
    "def app_fermeture():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    taille_ele_struct = element_structurant_dialog()\n",
    "    element_structurant = cv2.getStructuringElement(cv2.MORPH_RECT, (taille_ele_struct,taille_ele_struct))\n",
    "    image_ferneture = cv2.morphologyEx(image_opencv, cv2.MORPH_CLOSE,element_structurant) \n",
    "    afficher_image_resultante(image_ferneture)\n",
    "    \n",
    "def app_selection_par_rectangle():\n",
    "    global chemin_image_originale\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    if(image_opencv.shape[0] <= 400):\n",
    "        image_opencv = cv2.resize(image_opencv,(image_opencv.shape[1]*2,image_opencv.shape[0]*2))\n",
    "    if(int(image_opencv.shape[0]/2) >= 350):\n",
    "        image_opencv = cv2.resize(image_opencv,(int(image_opencv.shape[1]/2),int(image_opencv.shape[0]/2)))\n",
    "    r1 = messagebox.showinfo(\"Sélection\", 'Veuillez sélectionner une région et cliquer sur le bouton \"espace\" ou \"entrer\" pour voir la région sélectionnée')\n",
    "    if r1 == \"ok\":\n",
    "        # Sélectionner la région d'intérêt\n",
    "        roi = cv2.selectROI(image_opencv)\n",
    "        # Extraire la région d'intérêt\n",
    "        image_opencv = image_opencv[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "        # Afficher la région d'intérêt\n",
    "        afficher_image_resultante(image_opencv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b711e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtres moyenneur, median, gaussien\n",
    "\n",
    "def filter_size_dialog():\n",
    "    #fenetre.withdraw()  # cache la fenêtre principale\n",
    "    size = simpledialog.askinteger(\"Taille du filtre\", \"Entrez la taille du filtre : \", minvalue=1, maxvalue=100)\n",
    "    if size is None:\n",
    "        # affiche un message d'erreur si la taille est nulle\n",
    "        messagebox.showerror(\"Erreur\", \"La taille ne peut pas être nulle.\")\n",
    "    elif not isinstance(size, int):\n",
    "        # affiche un message d'erreur si la taille n'est pas un entier\n",
    "        messagebox.showerror(\"Erreur\", \"La taille doit être un entier.\")\n",
    "    else :\n",
    "        #fenetre.deiconify()  # affiche la fenêtre principale\n",
    "        return size\n",
    "    \n",
    "def filtre_moyenneur():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    kernel_size = filter_size_dialog()\n",
    "    # Application du filtre moyenneur\n",
    "    img_filtered = cv2.blur(image_opencv, (kernel_size, kernel_size))\n",
    "    afficher_image_resultante(img_filtered)\n",
    "\n",
    "def filtre_median():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    kernel_size = filter_size_dialog()\n",
    "    # Application du filtre median\n",
    "    img_filtered = cv2.medianBlur(image_opencv, kernel_size)\n",
    "    afficher_image_resultante(img_filtered)\n",
    "\n",
    "def sigma_value_dialog():\n",
    "    sigma = simpledialog.askfloat(\"Valeur de l'écart-type\", \"Entrez la valeur de l'écart-type : \")\n",
    "    if sigma is None:\n",
    "        messagebox.showerror(\"Erreur\", \"L'écart-type ne peut pas être nulle.\")\n",
    "    elif not isinstance(sigma, float):\n",
    "        messagebox.showerror(\"Erreur\", \"L'écart-type doit être de type decimal.\")\n",
    "    else :\n",
    "        return sigma\n",
    "\n",
    "def filtre_gaussien():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    sigma = sigma_value_dialog()\n",
    "    # Création du noyau de filtre gaussien\n",
    "    kernel_size = int(3 * sigma)\n",
    "    if kernel_size % 2 == 0:\n",
    "        kernel_size += 1\n",
    "    kernel = cv2.getGaussianKernel(kernel_size, sigma)\n",
    "    kernel = np.outer(kernel, kernel.transpose())\n",
    "    # Application du filtre gaussien\n",
    "    img_filtered = cv2.filter2D(image_opencv, -1, kernel)\n",
    "    afficher_image_resultante(img_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e86ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction de contours\n",
    "\n",
    "def sobel_contours():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    image_opencv = cv2.imread(chemin_image_originale)\n",
    "    # Convertit l'image en niveau de gris\n",
    "    image_opencv = cv2.cvtColor(image_opencv, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer le gradient en utilisant le filtre de Sobel\n",
    "    sobel_x = cv2.Sobel(image_opencv, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image_opencv, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_x=cv2.convertScaleAbs(sobel_x)\n",
    "    sobel_y=cv2.convertScaleAbs(sobel_y)\n",
    "    sobel_img = cv2.addWeighted(sobel_x, 0.5, sobel_y, 0.5, 0)\n",
    "    afficher_image_resultante(sobel_img)\n",
    "\n",
    "def gradient_contours():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer le gradient de l'image\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    gradient = cv2.addWeighted(grad_x, 0.5, grad_y, 0.5, 0)\n",
    "    # Appliquer un seuillage pour obtenir des contours binaires\n",
    "    _, binary = cv2.threshold(gradient, 0, 255, cv2.THRESH_BINARY)\n",
    "    afficher_image_resultante(binary)\n",
    "\n",
    "def robert_contours():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculer les gradients selon x et y avec le filtre Robert\n",
    "    robert_x = cv2.filter2D(gray, -1, np.array([[0, 0], [0, 1]]))\n",
    "    robert_y = cv2.filter2D(gray, -1, np.array([[0, 0], [1, 0]]))\n",
    "    # Combinaison des deux gradients pour obtenir l'image des contours\n",
    "    robert = cv2.addWeighted(robert_x, 0.5, robert_y, 0.5, 0)\n",
    "    # Appliquer un seuillage pour obtenir des contours binaires\n",
    "    _, binary = cv2.threshold(robert, 0, 255, cv2.THRESH_BINARY)\n",
    "    afficher_image_resultante(binary)\n",
    "    \n",
    "def laplacian_contours():\n",
    "    global tkimage2, chemin_image_originale\n",
    "    # lire l'image\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculer l'image du Laplacien\n",
    "    laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "    # Appliquer un seuillage pour obtenir des contours binaires\n",
    "    _, binary = cv2.threshold(laplacian, 0, 255, cv2.THRESH_BINARY)\n",
    "    afficher_image_resultante(binary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d794d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_croissanceD():\n",
    "    global chemin_image_originale\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    seed = (50,50)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(gray)\n",
    "    points_to_add = [seed]\n",
    "    while len(points_to_add) > 0:\n",
    "        pt = points_to_add[0]\n",
    "        points_to_add = points_to_add[1:]\n",
    "        if pt[0] >= 0 and pt[0] < gray.shape[1] and pt[1] >= 0 and pt[1] < gray.shape[0] and mask[pt[1], pt[0]] == 0:\n",
    "            if abs(int(gray[pt[1], pt[0]]) - int(gray[seed[1], seed[0]])) <= 50:\n",
    "                mask[pt[1], pt[0]] = 255\n",
    "                points_to_add.append((pt[0] + 1, pt[1]))\n",
    "                points_to_add.append((pt[0] - 1, pt[1]))\n",
    "                points_to_add.append((pt[0], pt[1] + 1))\n",
    "                points_to_add.append((pt[0], pt[1] - 1))\n",
    "    img = mask\n",
    "    afficher_image_resultante(img)\n",
    "    \n",
    "def app_partitionD():\n",
    "    global chemin_image_originale\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "    markers = markers + 1\n",
    "    markers[unknown==255] = 0\n",
    "\n",
    "    markers = cv2.watershed(img, markers)\n",
    "    image_out = np.zeros_like(img)\n",
    "    image_out[markers == -1] = [255,0,0]  # Marquer les bords avec une couleur rouge\n",
    "\n",
    "    afficher_image_resultante(image_out)\n",
    "    \n",
    "def app_KMeansSegmentation():\n",
    "    global chemin_image_originale\n",
    "    img = cv2.imread(chemin_image_originale)\n",
    "    img = np.array(img)\n",
    "\n",
    "    Z = img.reshape((-1,3))\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 8\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "    \n",
    "    afficher_image_resultante(res2)\n",
    "\n",
    " \n",
    "def threshold_value_dialog():\n",
    "    threshold = simpledialog.askinteger(\"Valeur du seuil\", \"Entrez la valeur du seuil : \", minvalue=0, maxvalue=255)\n",
    "    if threshold is None:\n",
    "        messagebox.showerror(\"Erreur\", \"Le seuil ne peut pas être nulle.\")\n",
    "    elif not isinstance(threshold, int):\n",
    "        messagebox.showerror(\"Erreur\", \"L'écart-type doit être de type entier.\")\n",
    "    else :\n",
    "        return threshold\n",
    "    \n",
    "def detect_points_of_interest():\n",
    "    global chemin_image_originale\n",
    "    image = cv2.imread(chemin_image_originale)\n",
    "    \n",
    "    threshold = threshold_value_dialog()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "    \n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold)\n",
    "    \n",
    "    points_of_interest = []\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        points_of_interest.append(((x1+x2)//2, (y1+y2)//2))\n",
    "    \n",
    "    poi_image = np.zeros_like(image)\n",
    "    for poi in points_of_interest:\n",
    "        cv2.circle(poi_image, poi, 5, (0, 0, 255), -1)\n",
    "    result = cv2.addWeighted(image, 0.5, poi_image, 0.5, 0)\n",
    "    afficher_image_resultante(result) \n",
    "    \n",
    "    \n",
    "\n",
    "def lzw_compress():\n",
    "    global chemin_image_originale\n",
    "    image = cv2.imread(chemin_image_originale)\n",
    "\n",
    "   # image=self.original_image\n",
    "\n",
    "    # Convert the image to a 1D array of bytes\n",
    "    data = image.flatten().astype(np.uint8).tolist()\n",
    "\n",
    "    # Initialize the dictionary with single-byte entries\n",
    "    dictionary = {chr(i): i for i in range(256)}\n",
    "\n",
    "    # Initialize variables for encoding\n",
    "    result = []\n",
    "    buffer = \"\"\n",
    "    next_code = 256\n",
    "\n",
    "    # Iterate over the input data\n",
    "    for symbol in data:\n",
    "        new_buffer = buffer + chr(symbol)\n",
    "\n",
    "        # Check if the new symbol is in the dictionary\n",
    "        if new_buffer in dictionary:\n",
    "            buffer = new_buffer\n",
    "        else:\n",
    "            # Output the code for the current buffer\n",
    "            result.append(dictionary[buffer])\n",
    "\n",
    "            # Add the new symbol to the dictionary\n",
    "            dictionary[new_buffer] = next_code\n",
    "            next_code += 1\n",
    "\n",
    "            # Reset the buffer\n",
    "            buffer = chr(symbol)\n",
    "\n",
    "    # Output the code for the last buffer\n",
    "    if buffer:\n",
    "        result.append(dictionary[buffer])\n",
    "\n",
    "    # Convert the output to a NumPy array\n",
    "    result = np.array(result, dtype=np.uint16)\n",
    "\n",
    "    # Pack the output into bytes and return\n",
    "    success, encoded = cv2.imencode('.png', result)\n",
    "    return encoded.tobytes()\n",
    "\n",
    "def compress_lzw():\n",
    "\n",
    "    file = filedialog.asksaveasfile(mode='wb', defaultextension=\".jpg\")\n",
    "    if file:\n",
    "        compressed_data= lzw_compress()\n",
    "        # Write the compressed data to the selected file and close it\n",
    "        file.write(compressed_data)\n",
    "        file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c7d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_shape : 3 and shape = (1115, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "# la fenetre de notre application \n",
    "fenetre = Tk()\n",
    "fenetre.title(\"vision par ordinateur\")\n",
    "fenetre.geometry(\"1800x700\")\n",
    "\n",
    "menuBar=Menu(fenetre)\n",
    "fenetre.config(menu=menuBar)\n",
    "\n",
    "def f_image_negative():\n",
    "    label2.config(text='===> ===> ===>\\nl’image négative\\n===> ===> ===>')\n",
    "    but3.config(command=app_image_negative)\n",
    "    \n",
    "def f_rotation_degree():\n",
    "    label2.config(text='===> ===> ===>\\nRotation (degree)\\n===> ===> ===>')\n",
    "    but3.config(command=app_rotation_degree)\n",
    "    \n",
    "def f_Redimensionner_nouvelletaille():\n",
    "    label2.config(text='===> ===> ===>\\nRedimensionner\\n===> ===> ===>')\n",
    "    but3.config(command=app_Redimensionner_nouvelletaille)\n",
    "    \n",
    "def f_Redimensionner_pourcentage():\n",
    "    label2.config(text='===> ===> ===>\\nRedimensionner\\n===> ===> ===>')\n",
    "    but3.config(command=app_Redimensionner_pourcentage)\n",
    "    \n",
    "def f_selection_par_rectangle():\n",
    "    label2.config(text='===> ===> ===>\\npar rectangle\\n===> ===> ===>')\n",
    "    but3.config(command=app_selection_par_rectangle)\n",
    "    \n",
    "def f_histogramme():\n",
    "    label2.config(text='===> ===> ===>\\nHistogramme\\n===> ===> ===>')\n",
    "    but3.config(command=app_histogramme)\n",
    "    \n",
    "def f_egalisation():\n",
    "    label2.config(text='===> ===> ===>\\nEgalisation\\n===> ===> ===>')\n",
    "    but3.config(command=app_egalisation)\n",
    "    \n",
    "def f_etirement():\n",
    "    label2.config(text='===> ===> ===>\\nEtirement\\n===> ===> ===>')\n",
    "    but3.config(command=app_etirement)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Transformation\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"l’image négative\", command=f_image_negative, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Rotation (degree)\", command=f_rotation_degree, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Redimensionner(nouvelle taille)\", command=f_Redimensionner_nouvelletaille, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Redimensionner(pourcentage)\", command=f_Redimensionner_pourcentage, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Sélectionner une zone par rectangle\", command=f_selection_par_rectangle, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Sélectionner une zone par sélection libre\", command=f_selection_par_rectangle, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"l’histogramme\", command=f_histogramme, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Egalisation\", command=f_egalisation, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Etirement\", command=f_etirement, font=(\"Arial\", 12))\n",
    "\n",
    "def f_binarisation_globale_seuillage_manuel():\n",
    "    label2.config(text='===> ===> ===>\\nSeuillage manuel\\n===> ===> ===>')\n",
    "    but3.config(command=app_binarisation_globale_seuillage_manuel)\n",
    " \n",
    "def f_binarisation_globale_algorithme_Otsu():\n",
    "    label2.config(text='===> ===> ===>\\nAlgorithme d’Otsu\\n===> ===> ===>')\n",
    "    but3.config(command=app_binarisation_globale_algorithme_Otsu)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"binarisation globale\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Seuillage manuel\", command=f_binarisation_globale_seuillage_manuel, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"l’algorithme d’Otsu\", command=f_binarisation_globale_algorithme_Otsu, font=(\"Arial\", 12))\n",
    "\n",
    "# Code Lalle\n",
    "def f_filtre_moyenneur():\n",
    "    label2.config(text='===> ===> ===>\\nFiltre Moyenneur\\n===> ===> ===>')\n",
    "    but3.config(command=filtre_moyenneur)\n",
    "def f_filtre_median():\n",
    "    label2.config(text='===> ===> ===>\\nFiltre Médian\\n===> ===> ===>')\n",
    "    but3.config(command=filtre_median)\n",
    "def f_filtre_gaussien():\n",
    "    label2.config(text='===> ===> ===>\\nFiltre Gaussien\\n===> ===> ===>')\n",
    "    but3.config(command=filtre_gaussien)\n",
    "\n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Appliquer un Filtre\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Gaussien\", command=f_filtre_gaussien, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Moyenneur\", command=f_filtre_moyenneur, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Médian\", command=f_filtre_median, font=(\"Arial\", 12))\n",
    "\n",
    "# Code Lalle\n",
    "def f_sobel():\n",
    "    label2.config(text='===> ===> ===>\\nSobel\\n===> ===> ===>')\n",
    "    but3.config(command=sobel_contours)\n",
    "def f_gradient():\n",
    "    label2.config(text='===> ===> ===>\\nGradient\\n===> ===> ===>')\n",
    "    but3.config(command=gradient_contours)\n",
    "def f_robert():\n",
    "    label2.config(text='===> ===> ===>\\nRobert\\n===> ===> ===>')\n",
    "    but3.config(command=robert_contours)\n",
    "def f_laplacien():\n",
    "    label2.config(text='===> ===> ===>\\nLaplacien\\n===> ===> ===>')\n",
    "    but3.config(command=laplacian_contours)\n",
    "\n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Extraire des contours\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Gradient\", command=f_gradient, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Sobel\", command=f_sobel, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Robert\", command=f_robert, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Laplacien\", command=f_laplacien, font=(\"Arial\", 12))\n",
    "\n",
    "def f_delatation():\n",
    "    label2.config(text='===> ===> ===>\\nDilatation\\n===> ===> ===>')\n",
    "    but3.config(command=app_delatation)\n",
    "    \n",
    "def f_erosion():\n",
    "    label2.config(text='===> ===> ===>\\nErosion\\n===> ===> ===>')\n",
    "    but3.config(command=app_erosion)\n",
    "    \n",
    "def f_ouverture():\n",
    "    label2.config(text='===> ===> ===>\\nOuverture\\n===> ===> ===>')\n",
    "    but3.config(command=app_ouverture)\n",
    "    \n",
    "def f_fermeture():\n",
    "    label2.config(text='===> ===> ===>\\nFermeture\\n===> ===> ===>')\n",
    "    but3.config(command=app_fermeture)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Morphologie Mathématique\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Erosion\", command=f_erosion, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Dilatation\", command=f_delatation, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Ouverture\", command=f_ouverture, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Fermeture\", command=f_fermeture, font=(\"Arial\", 12))\n",
    "\n",
    "\n",
    "def f_croissanceD():\n",
    "    label2.config(text='===> ===> ===>\\ncroissanceD\\n===> ===> ===>')\n",
    "    but3.config(command=app_croissanceD)\n",
    "def f_partitionD():\n",
    "    label2.config(text='===> ===> ===>\\npartitionD\\n===> ===> ===>')\n",
    "    but3.config(command=app_partitionD)\n",
    "def f_KMeansSegmentation():\n",
    "    label2.config(text='===> ===> ===>\\nKMeansSegmentatione\\n===> ===> ===>')\n",
    "    but3.config(command=app_KMeansSegmentation)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Segmentation\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Croissance de régions D\", command=f_croissanceD, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Partition de regions D\", command=f_partitionD, font=(\"Arial\", 12))\n",
    "menu_sous.add_command(label=\"Méthode des k-means\", command=f_KMeansSegmentation, font=(\"Arial\", 12))\n",
    "    \n",
    "def f_points_of_interest():\n",
    "    label2.config(text='===> ===> ===>\\n Points d\\'intérêt Hough \\n===> ===> ===>')\n",
    "    but3.config(command=detect_points_of_interest)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Points d’intérêt\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"Hough\", command=f_points_of_interest, font=(\"Arial\", 12))\n",
    "\n",
    "def f_lzw_compress():\n",
    "    label2.config(text='===> ===> ===>\\n Compression LZW \\n===> ===> ===>')\n",
    "    but3.config(command=compress_lzw)\n",
    "    \n",
    "menu_sous = Menu(menuBar, tearoff=False)\n",
    "menuBar.add_cascade(label=\"Compression\", menu=menu_sous)\n",
    "menu_sous.add_command(label=\"LZW\", command=f_lzw_compress, font=(\"Arial\", 12))\n",
    "\n",
    "\n",
    "# Charger les images\n",
    "chemin_image_originale=\"default-image.png\"\n",
    "image1 = Image.open(chemin_image_originale)\n",
    "image2 = Image.open(chemin_image_originale)\n",
    "\n",
    "image1=image1.resize((500, 500), Image.ANTIALIAS)\n",
    "image2=image2.resize((500, 500), Image.ANTIALIAS)\n",
    "\n",
    "# Convertir les images en format compatible avec Tkinter\n",
    "tkimage1 = ImageTk.PhotoImage(image1)\n",
    "tkimage2 = ImageTk.PhotoImage(image2)\n",
    "\n",
    "# Créer deux canevas côte à côte\n",
    "canvas1 = Canvas(fenetre, width=500, height=500)\n",
    "canvas2 = Canvas(fenetre, width=500, height=500)\n",
    "\n",
    "canvas1.place(x=20,y=80)\n",
    "canvas2.place(x=830,y=80)\n",
    "\n",
    "# Afficher les images dans les canevas\n",
    "canvas1_image = canvas1.create_image(0, 0, anchor=NW, image=tkimage1)\n",
    "canvas2_image = canvas2.create_image(0, 0, anchor=NW, image=tkimage2)\n",
    "\n",
    "but1=Button(fenetre,text='Selectionnez une image',font=('courrier',9),command=parcourir_image)\n",
    "but1.place(x=20,y=20)\n",
    "\n",
    "but2=Button(fenetre,text='sauvegarder l\\'image',font=('courrier',15),command=sauvegarder)\n",
    "but2.place(x=990,y=600)\n",
    "\n",
    "but3=Button(fenetre,text='Appliquer le traitement',font=('courrier',15),command=ma_fonction1)\n",
    "but3.place(x=570,y=20)\n",
    "\n",
    "label1=Label(fenetre,text='image originale',fg='#41B77F',font=('courrier',20))\n",
    "label1.place(x=170,y=40)\n",
    "\n",
    "label2=Label(fenetre,text='image résultante',fg='#41B77F',font=('courrier',20))\n",
    "label2.place(x=990,y=40)\n",
    "\n",
    "label2=Label(fenetre,text='===> ===> ===>\\n===> ===> ===>',font=('courrier',20))\n",
    "label2.place(x=570,y=300)\n",
    "\n",
    "fenetre.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ad891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c85db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e97524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92787b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781be76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b074fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5668b6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792924e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
